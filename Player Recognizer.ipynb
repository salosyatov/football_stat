{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageStandardizer:\n",
    "    from PIL import Image\n",
    "    import numpy as np    \n",
    "    def __init__(self, max_thumb_size):\n",
    "        self.max_thumb_size = max_thumb_size\n",
    "    def array_from_file(self, filepath):\n",
    "\n",
    "        with Image.open(filepath) as image:\n",
    "            blank_image = Image.new('RGB', self.max_thumb_size, 'black')\n",
    "            image.thumbnail(self.max_thumb_size, Image.BICUBIC)\n",
    "            blank_image.paste(image, (0,0)) # add to left upper corner\n",
    "            return np.asarray(blank_image)\n",
    "    def array_from_file_list(self, filepaths):\n",
    "        res=[]\n",
    "        for filepath in filepaths:\n",
    "            with Image.open(filepath) as image:\n",
    "                blank_image = Image.new('RGB', self.max_thumb_size, 'black')\n",
    "                image.thumbnail(self.max_thumb_size, Image.BICUBIC)\n",
    "                blank_image.paste(image, (0,0)) # add to left upper corner\n",
    "                res.append(np.asarray(blank_image))\n",
    "        return np.asarray(res)\n",
    "            \n",
    "            \n",
    "    def save_to_image_file(self, image, output_image_path):\n",
    "        image.save(output_image_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models , optimizers , losses ,activations , callbacks\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2 = MobileNetV2(input_shape=(160,64,3),include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'out_relu_1/Relu6:0' shape=(None, 5, 2, 1280) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobileNetV2.get_output_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    basic_net = Sequential([mobileNetV2,Flatten(), Dense( 256 )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x288ec933390>,\n",
       " <keras.layers.core.Flatten at 0x288eca30d68>,\n",
       " <keras.layers.core.Dense at 0x288eca30da0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        for layer in basic_net.layers[0].layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        input_x1 = Input( shape=(160,64,3))\n",
    "        input_x2 = Input( shape=(160,64,3) )\n",
    "\n",
    "        output_x1 = basic_net( input_x1 )\n",
    "        output_x2 = basic_net( input_x2 )\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "        seq_similarity_model = [\n",
    "            Lambda( lambda tensors : K.abs( tensors[0] - tensors[1] )),\n",
    "            #Lambda( lambda a, b : K.abs( a - b )),\n",
    "            #Lambda( lambda tensors : K.abs( tensors)),\n",
    "            Dense( 1 , activation=activations.sigmoid)\n",
    "        ]\n",
    "        similarity_model1 =  Sequential( seq_similarity_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer lambda_1 is not connected, no input to return.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e77bcea067c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimilarity_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36minput\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             raise AttributeError('Layer ' + self.name +\n\u001b[1;32m--> 822\u001b[1;33m                                  ' is not connected, no input to return.')\n\u001b[0m\u001b[0;32m    823\u001b[0m         return self._get_node_attribute_at_index(0, 'input_tensors',\n\u001b[0;32m    824\u001b[0m                                                  'input')\n",
      "\u001b[1;31mAttributeError\u001b[0m: Layer lambda_1 is not connected, no input to return."
     ]
    }
   ],
   "source": [
    "similarity_model1.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'sequential_1/dense_1/BiasAdd:0' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'sequential_1_1/dense_1/BiasAdd:0' shape=(None, 256) dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[output_x1, output_x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xs = K.stack([output_x1, output_x2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = similarity_model1(inputs=output_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Euc_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n",
    "# use and add the distance function\n",
    "Euc_distance = Euc_layer([output_x1, output_x2])\n",
    "#identify the prediction\n",
    "FC = Dense(1,activation='sigmoid')\n",
    "prediction = FC(Euc_distance)\n",
    "#Define the network with the left and right inputs and the ouput prediction\n",
    "siamese_net = models.Model(inputs=[input_x1, input_x2],outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FC.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'sequential_20/dense_21/BiasAdd:0' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'sequential_20_1/dense_21/BiasAdd:0' shape=(None, 256) dtype=float32>]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[output_x1, output_x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_inbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-949aa970ac02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_x1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_x2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minput_x1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_x2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[1;32m--> 241\u001b[1;33m             self.inputs, self.outputs)\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1432\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1434\u001b[1;33m                   tensor_index=tensor_index)\n\u001b[0m\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[1;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[1;32m-> 1421\u001b[1;33m                       node_index, tensor_index)\n\u001b[0m\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[1;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[0;32m   1391\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcycle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdetected\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \"\"\"\n\u001b[1;32m-> 1393\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m         \u001b[1;31m# Prevent cycles.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_inbound_nodes'"
     ]
    }
   ],
   "source": [
    "input_xs = K.stack([input_x1, input_x2], axis=1)\n",
    "model = models.Model( [input_x1, input_x2] , outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_inbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-2d3fe501da2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#outputs = similarity_model1([output_x1, output_x2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0minput_x1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0minput_x2\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[1;32m--> 241\u001b[1;33m             self.inputs, self.outputs)\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1432\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1434\u001b[1;33m                   tensor_index=tensor_index)\n\u001b[0m\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[1;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[1;32m-> 1421\u001b[1;33m                       node_index, tensor_index)\n\u001b[0m\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[1;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[0;32m   1391\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcycle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdetected\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \"\"\"\n\u001b[1;32m-> 1393\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m         \u001b[1;31m# Prevent cycles.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_inbound_nodes'"
     ]
    }
   ],
   "source": [
    "    #outputs = similarity_model1([output_x1, output_x2])\n",
    "\n",
    "    model = models.Model( [ input_x1 , input_x2 ] , outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THUMB_SIZE=(32,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.keras import models , optimizers , losses ,activations , callbacks\n",
    "#from tensorflow.python.keras.layers import *\n",
    "#import tensorflow.python.keras.backend as K\n",
    "from keras import models , optimizers , losses ,activations , callbacks\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras import Sequential\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "from PIL import Image\n",
    "#import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class Recognizer (object) :\n",
    "\n",
    "    def __init__( self, max_thumb_size, model=None ):\n",
    "        self.max_thumb_size = max_thumb_size\n",
    "        self.input_shape = (self.max_thumb_size[1], self.max_thumb_size[0], 3)                 \n",
    "        self.class_indices = {}\n",
    "        \n",
    "        if model:\n",
    "            self._model = model\n",
    "            #TODO: \n",
    "            return\n",
    "        \n",
    "        self._basic_model = self.basic_net_3()\n",
    "        self._similarity_model = self.similarity_model()\n",
    "\n",
    "        input_x1 = Input( shape=self.input_shape )\n",
    "        input_x2 = Input( shape=self.input_shape )\n",
    "\n",
    "        output_x1 = self._basic_model( input_x1 )\n",
    "        output_x2 = self._basic_model( input_x2 )\n",
    "        \n",
    "        self.euc_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n",
    "        euc_distance = self.euc_layer([output_x1, output_x2])\n",
    "        self.finalFC = Dense(1, activation='sigmoid')\n",
    "        prediction = self.finalFC(euc_distance)\n",
    "        self._model = models.Model(inputs=[input_x1, input_x2],outputs=prediction)\n",
    "\n",
    "        #it doesn't work when specifying optimizer through  class     self._model.compile( loss=losses.binary_crossentropy , optimizer=optimizers.Adam(lr=0.0001))\n",
    "        adam = optimizers.Adam(lr=0.001)\n",
    "        self._model.compile( loss=losses.binary_crossentropy , optimizer=adam, metrics=['accuracy'])\n",
    "        #self._model.compile(optimizer='sgd', loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
    "        \n",
    "    def basic_net(self):\n",
    "        kernel_size_1 = ( 3 , 3 )\n",
    "        kernel_size_2 = ( 3 , 3 )\n",
    "        pool_size_1 = ( 3 , 3 )\n",
    "        pool_size_2 = ( 2 , 2 )\n",
    "        strides_1 = 2\n",
    "        strides_2 = 1\n",
    "        \n",
    "        seq_conv_model = [\n",
    "            Conv2D( 32, kernel_size=(11,11) , strides=2 , activation=activations.relu, input_shape=self.input_shape ),\n",
    "            MaxPooling2D(),\n",
    "            \n",
    "            Conv2D( 64, kernel_size=(5,5) , strides=1 , activation=activations.relu ),\n",
    "            MaxPooling2D(),\n",
    "          \n",
    "            #Conv2D( 256, kernel_size=(3,3) , strides=1 , activation=activations.relu ),\n",
    "           \n",
    "            Conv2D( 128, kernel_size=(3,3) , strides=1 , activation=activations.relu ),\n",
    "            MaxPooling2D(),\n",
    "         \n",
    "            #Conv2D( 128, kernel_size=(3,3) , strides=1 , activation=activations.relu ),\n",
    "            #MaxPooling2D(),\n",
    "            Flatten(),\n",
    "            Dense( 512 , activation=activations.relu ),\n",
    "            Dense( 64 , activation=activations.relu ) \n",
    "        ]\n",
    "        seq_model = Sequential( seq_conv_model )\n",
    "        return seq_model\n",
    "    \n",
    "    def basic_net_2(self):\n",
    "        kernel_size_1 = ( 3 , 3 )\n",
    "        kernel_size_2 = ( 3 , 3 )\n",
    "        pool_size_1 = ( 3 , 3 )\n",
    "        pool_size_2 = ( 2 , 2 )\n",
    "        strides_1 = 2\n",
    "        strides_2 = 1\n",
    "        \n",
    "        seq_conv_model = [\n",
    "            Conv2D( 8, kernel_size=kernel_size_1 , strides=strides_1 , activation=activations.relu, input_shape=self.input_shape ),\n",
    "            MaxPooling2D(pool_size=pool_size_1, strides=strides_1 ),\n",
    "\n",
    "            Conv2D( 16, kernel_size=kernel_size_2 , strides=strides_2 , activation=activations.relu ),\n",
    "            MaxPooling2D(pool_size=pool_size_2 , strides=strides_2),\n",
    "\n",
    "            Flatten(),\n",
    "            Dense( 50 , activation=activations.sigmoid )\n",
    "        ]\n",
    "        seq_model = keras.Sequential( seq_conv_model )\n",
    "        return seq_model\n",
    "    def basic_net_3(self):        \n",
    "        mobileNetV2 = MobileNetV2(input_shape=self.input_shape,include_top=False)\n",
    "        for layer in mobileNetV2.layers:\n",
    "            layer.trainable = False\n",
    "        return Sequential([mobileNetV2, Flatten(), Dense( 64 )])\n",
    "\n",
    "    def similarity_model(self):\n",
    "        seq_similarity_model = [\n",
    "            Lambda( lambda tensors : K.abs( tensors[0] - tensors[1] )),\n",
    "            Dense( 1 , activation=activations.sigmoid)\n",
    "        ]\n",
    "        return Sequential( seq_similarity_model )\n",
    "\n",
    "    def fit(self, X, Y ,   **kwargs  ):\n",
    "        X1 = X[:,0,:,:,:]\n",
    "        X2 = X[:,1,:,:,:]\n",
    "        initial_time = time.time()\n",
    "        self._model.fit( [X1,X2] , Y , **kwargs)                     \n",
    "        final_time = time.time()\n",
    "        \n",
    "        eta = ( final_time - initial_time )\n",
    "        time_unit = 'seconds'\n",
    "        if eta >= 60 :\n",
    "            eta = eta / 60\n",
    "            time_unit = 'minutes'\n",
    "        self._model.summary( )\n",
    "        print( 'Elapsed time acquired -> {} {}'.format(  eta , time_unit ) )\n",
    "        \n",
    "    def fit_generator(self, train_generator ,  **kwargs  ):\n",
    "        #TODO: to implement\n",
    "        pass\n",
    "\n",
    "\n",
    "    def calc_embeddings(self, dir_path, save_path='./embeddings.npy'):\n",
    "        self.mapping_files=[]\n",
    "        self.mapping_classes=[]\n",
    "        arrays=[]\n",
    "        sub_dirs = [f.name for f in os.scandir(dir_path) if f.is_dir()]\n",
    "        for sd in sub_dirs:\n",
    "            files =  [f.path for f in os.scandir(os.path.join(dir_path, sd)) if f.is_file()]\n",
    "            if any(files):\n",
    "                arrays.append( recognizer._basic_model.predict(ImageStandardizer(max_thumb_size).array_from_file_list(files)/255))\n",
    "                mapping_files.extend(files)\n",
    "                mapping_classes.extend([sd] * len(files))\n",
    "        self.all_embeddings = np.vstack(tuple(arrays))\n",
    "        if save_path:\n",
    "            np.save(save_path, self.all_embeddings)\n",
    "        \n",
    "    def prepare_images_from_dir( self , dir_path , save_intermediate = True) :\n",
    "        self.labels_dict={}\n",
    "        self.labels_list=[]\n",
    "        imageStandardizer = ImageStandardizer(self.max_thumb_size)  \n",
    "        sub_dirs = [f.name for f in os.scandir(dir_path) if f.is_dir()]\n",
    "        count=0\n",
    "        arrays_per_label=[]\n",
    "        for sd in sub_dirs:\n",
    "            self.labels_dict[sd] = count\n",
    "            self.labels_list.append(sd)\n",
    "            \n",
    "            files =  [f.path for f in os.scandir(os.path.join(dir_path, sd)) if f.is_file()]\n",
    "            arrays_per_label.append(imageStandardizer.array_from_file_list(files)/255)\n",
    "            count+=1   \n",
    "        \n",
    "        if save_intermediate:\n",
    "            with open('arrays_per_label.pkl', 'wb') as file:\n",
    "                pickle.dump(arrays_per_label, file)\n",
    "        \n",
    "        #TODO: add shuffling\n",
    "        return arrays_per_label\n",
    "    \n",
    "    def prepare_pairs(self, arrays_per_label):\n",
    "        x_genuine_pair=[]\n",
    "        y_genuine=[]\n",
    "\n",
    "        for label_arrays in arrays_per_label:\n",
    "            len_arrays = len(label_arrays)\n",
    "            for i in range(0, len_arrays-1):\n",
    "                for j in range(i+1, len_arrays):\n",
    "                    x_genuine_pair.append([label_arrays[i], label_arrays[j]])\n",
    "                    y_genuine.append(1)\n",
    "                \n",
    "\n",
    "        x_imposite_pair=[]\n",
    "        y_imposite=[]\n",
    "                      \n",
    "        for _ in range(self.imposite_pair_count):\n",
    "            class_count = len(arrays_per_label)\n",
    "            i, j = np.random.randint(0, class_count, 2)\n",
    "            if i != j:\n",
    "                if len(arrays_per_label[i]) > 0 and len(arrays_per_label[j]) > 0:\n",
    "                    i1 = np.random.randint(0, len(arrays_per_label[i]))\n",
    "                    j1 = np.random.randint(0, len(arrays_per_label[j]))\n",
    "\n",
    "                    x_imposite_pair.append([arrays_per_label[i][i1], arrays_per_label[j][j1]])\n",
    "                    y_imposite.append(0) \n",
    "                    \n",
    "\n",
    "        X = np.concatenate([np.array(x_genuine_pair, dtype=np.float32), np.array(x_imposite_pair, dtype=np.float32)], axis=0)      \n",
    "        Y = np.concatenate([np.array(y_genuine, dtype=np.float32), np.array(y_imposite, dtype=np.float32)], axis=0)        \n",
    "                \n",
    "        return X, Y\n",
    " \n",
    "    def evaluate(self , test_X , test_Y  ) :\n",
    "        X1 = test_X[:,0,:,:,:]\n",
    "        X2 = test_X[:,1,:,:,:]\n",
    "        return self._model.evaluate( [X1, X2] , test_Y)\n",
    "\n",
    "    def predict(self, X  ):\n",
    "        X1 = X[:,0,:,:,:]\n",
    "        X2 = X[:,1,:,:,:]\n",
    "        predictions = self._model.predict( [X1, X2])\n",
    "        return predictions\n",
    "\n",
    "    def summary(self):\n",
    "        self._model.summary()\n",
    "\n",
    "    def save_model(self , file_path ='model.h5'):\n",
    "        self._model.save(file_path )\n",
    "\n",
    "    def load_model(self , file_path ='model.h5'):\n",
    "        self._model = models.load_model(file_path)\n",
    "        self._basic_model = self._model.layers[2]\n",
    "        self._similarity_model = self._model.layers[-1]\n",
    "        \n",
    "recognizer = Recognizer(MAX_THUMB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x225e8b58be0>,\n",
       " <keras.layers.core.Flatten at 0x225e8b7a048>,\n",
       " <keras.layers.core.Dense at 0x225e8b58f28>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer._model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.save_model('m3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'd:\\ML\\data\\f'\n",
    "IMAGE_DIR  = os.path.join(DATA_DIR, 'images', \"out\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "del K\n",
    "import tensorflow.python.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.python.keras.backend' from 'D:\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow_core\\\\python\\\\keras\\\\backend.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.load_model('m3_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        mapping_files=[]\n",
    "        mapping_classes=[]\n",
    "        arrays=[]\n",
    "        dir_path = IMAGE_DIR\n",
    "        sub_dirs = [f.name for f in os.scandir(dir_path) if f.is_dir()]\n",
    "        for sd in sub_dirs:\n",
    "            files =  [f.path for f in os.scandir(os.path.join(dir_path, sd)) if f.is_file()]\n",
    "            if any(files):\n",
    "                arrays.append( recognizer._basic_model.predict(ImageStandardizer(MAX_THUMB_SIZE).array_from_file_list(files)/255))\n",
    "\n",
    "                mapping_files.extend(files)\n",
    "                mapping_classes.extend([sd] * len(files))\n",
    "        all_embeddings = np.vstack(tuple(arrays))\n",
    "        all_embeddings.shape\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "test_image_path = r'D:\\ML\\data\\f\\images\\out\\CAM00003_118e394ea6e44235925aac3af3d7f3c7.jpg'\n",
    "test_array = ImageStandardizer(MAX_THUMB_SIZE).array_from_file(test_image_path)/255\n",
    "recognizing = recognizer._basic_model.predict(np.expand_dims(test_array, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([205], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b =recognizer._similarity_model.layers[-1].get_weights()\n",
    "x=np.abs(all_embeddings- recognizing)\n",
    "scores = expit(np.dot(x,w)+b)\n",
    "scores = scores[:,0]\n",
    "scores.argsort()[-1:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([204.24582 , 179.14958 , 200.60437 , 210.33305 , 184.73126 ,\n",
       "       197.70135 , 212.80118 , 235.13535 , 206.56067 , 223.77353 ,\n",
       "       211.14041 , 226.8733  , 151.26743 , 172.78833 , 157.83691 ,\n",
       "       164.68001 , 144.15228 , 136.5698  , 156.05261 , 164.69475 ,\n",
       "       163.67218 , 138.77116 , 158.47293 , 151.85413 , 202.14146 ,\n",
       "       186.9679  , 201.5093  , 215.00026 , 196.45094 , 205.56407 ,\n",
       "       199.20813 , 211.24295 , 202.63396 , 208.54993 , 166.13788 ,\n",
       "       186.24974 , 163.69366 , 172.71667 , 167.81148 , 155.15485 ,\n",
       "       178.20052 , 171.74359 , 157.50061 , 257.0649  , 256.565   ,\n",
       "       248.10886 , 240.22864 , 259.11108 , 249.32346 , 258.76135 ,\n",
       "       248.12115 , 263.98993 , 252.29456 , 255.97473 , 258.52386 ,\n",
       "       264.17255 , 251.90892 , 259.83313 , 258.64313 , 163.7786  ,\n",
       "       191.94696 , 162.67422 , 160.01422 , 182.21606 , 161.9861  ,\n",
       "       177.63016 , 177.15811 , 162.2586  , 144.3855  , 154.88121 ,\n",
       "       191.81789 , 140.43857 , 193.04538 , 172.63387 , 167.06238 ,\n",
       "       168.9255  , 157.60962 , 169.20706 , 147.29077 , 194.35545 ,\n",
       "       226.31866 , 210.16644 , 224.71158 , 223.06465 , 201.76337 ,\n",
       "       220.62697 , 216.68808 , 212.7212  , 192.40775 , 192.1842  ,\n",
       "       200.83398 , 177.66994 , 208.94081 , 181.18419 , 207.47868 ,\n",
       "       197.77509 , 216.13159 , 202.01283 , 202.3416  , 209.52072 ,\n",
       "       156.38286 , 173.02545 , 171.42159 , 184.57703 , 200.58545 ,\n",
       "       178.49963 , 195.37288 , 190.18823 , 136.99092 , 138.81947 ,\n",
       "       151.04839 , 128.30292 , 123.8391  , 140.00175 , 132.1782  ,\n",
       "       121.8985  , 146.73206 , 133.98833 , 135.68892 , 137.47757 ,\n",
       "       122.955925, 133.53499 , 123.62067 , 109.28279 , 117.74876 ,\n",
       "       128.88568 , 118.82587 , 129.55713 , 120.20425 , 139.19691 ,\n",
       "       141.83331 , 111.325745, 137.4329  , 138.93494 , 135.75133 ,\n",
       "       135.64224 , 130.44122 , 151.36772 , 122.157196, 106.618225,\n",
       "       128.9015  , 140.65517 , 222.7721  , 207.54091 , 186.3226  ,\n",
       "       184.72491 , 181.89575 , 128.10571 , 144.74826 , 124.254196,\n",
       "       130.21954 , 114.28    , 129.63629 , 158.86519 , 143.54346 ,\n",
       "       138.57072 , 138.61824 , 134.69775 , 148.84558 , 153.66156 ,\n",
       "       128.70094 , 146.38403 , 174.44318 , 183.15979 , 201.99283 ,\n",
       "       198.45686 , 155.58624 , 141.34077 , 178.94942 , 157.59935 ,\n",
       "       178.49911 , 149.94687 , 132.20242 , 159.73126 , 164.3453  ,\n",
       "       138.00319 , 158.58267 , 163.76132 , 163.5402  , 147.5007  ,\n",
       "       160.58148 , 157.62234 , 188.14789 , 177.12827 , 173.27718 ,\n",
       "       163.1749  , 168.27203 , 158.26584 , 177.1824  , 150.68358 ,\n",
       "       169.31992 , 173.61928 , 185.39384 , 170.21312 , 178.49634 ,\n",
       "       169.63762 , 168.20175 , 174.98965 , 170.92831 , 167.9983  ,\n",
       "       179.58484 , 144.52759 , 151.84488 , 153.89853 , 162.45947 ,\n",
       "       156.04813 , 158.07196 , 149.03784 , 184.7165  , 179.21152 ,\n",
       "       177.81729 , 164.8511  , 158.08621 , 173.38773 , 154.18503 ,\n",
       "       192.77847 , 213.46935 , 193.98843 , 175.88962 , 190.76279 ,\n",
       "       206.03604 , 210.65312 , 213.87794 , 163.54858 , 186.6484  ,\n",
       "       203.08087 , 175.04385 , 206.0043  , 184.24246 , 165.42178 ,\n",
       "       201.57379 , 176.24338 , 207.9732  , 193.77481 , 223.03674 ,\n",
       "       197.42967 , 197.53992 , 183.55356 , 178.49539 , 199.5117  ,\n",
       "       204.52184 , 209.12085 , 199.4236  , 232.57489 , 219.88127 ,\n",
       "       227.05377 , 219.86243 , 236.27652 , 204.87746 , 201.14453 ,\n",
       "       182.6565  , 174.26932 , 185.41557 , 225.72015 , 173.72269 ,\n",
       "       184.58188 , 185.51007 , 198.72571 , 180.45575 , 151.23532 ,\n",
       "       188.35098 , 169.22641 , 169.26033 , 180.51816 , 180.22539 ,\n",
       "       188.55858 , 192.92154 , 184.70529 , 193.96744 , 194.37965 ,\n",
       "       210.98518 , 233.24295 , 210.41663 , 223.57115 , 225.98502 ,\n",
       "       234.50638 , 212.05801 , 230.40524 , 213.53163 , 226.76917 ,\n",
       "       222.03342 , 220.05852 , 211.25995 , 204.225   , 222.4325  ,\n",
       "       220.7174  , 215.9974  , 221.78546 , 215.34712 , 211.95473 ,\n",
       "       187.06195 , 176.74512 , 188.92361 , 185.04059 , 178.56412 ,\n",
       "       211.93648 , 206.31389 , 215.427   , 198.78612 , 201.63596 ,\n",
       "       198.38098 , 193.66656 , 184.31085 , 203.3306  , 225.52487 ,\n",
       "       202.55    , 202.5859  , 211.88426 , 205.21793 , 207.02303 ,\n",
       "       177.43445 , 183.41772 , 189.90384 , 173.42526 , 205.8264  ,\n",
       "       203.89017 , 186.8985  , 229.91086 , 214.29335 , 240.40074 ,\n",
       "       216.27882 , 217.08781 , 228.84293 , 208.28796 , 222.75726 ,\n",
       "       224.10043 , 209.52629 , 226.43494 , 219.51132 ,  28.263607,\n",
       "        58.85704 , 129.24771 , 114.13103 , 136.51013 ,  31.50689 ,\n",
       "       116.9211  ,  79.031265,  70.66495 ,  54.546005,  94.017426,\n",
       "        54.776432,  65.75677 , 108.298584,  93.15187 ,  87.77101 ,\n",
       "       102.54134 ,  67.39283 ,  85.58299 ,  90.93042 , 111.37703 ,\n",
       "        82.51675 ,  74.90189 ,  72.50946 ,  49.435547,  68.17413 ,\n",
       "        87.01162 ,  37.920395, 397.62646 , 377.87274 , 468.5833  ,\n",
       "       397.35822 , 369.91693 , 417.07532 , 363.26376 , 382.86902 ,\n",
       "       479.87756 , 375.13995 , 396.35968 , 455.6513  , 450.6342  ,\n",
       "       392.1315  ], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00779243e-06, 1.68552768e-04, 1.80405220e-06, 3.33428834e-05,\n",
       "       1.58100590e-07, 2.28934582e-07, 3.43359581e-08, 2.48327797e-06,\n",
       "       1.60541617e-07, 2.20813035e-06, 1.49112327e-06, 1.18685698e-07,\n",
       "       7.54416704e-01, 5.27473427e-02, 1.95540246e-02, 1.47834967e-03,\n",
       "       8.87076318e-01, 4.76872735e-03, 6.30598962e-01, 8.70609701e-01,\n",
       "       8.60538721e-01, 2.92616606e-01, 8.06221783e-01, 9.61953521e-01,\n",
       "       7.03636260e-07, 4.21358628e-08, 8.62632760e-07, 4.65848598e-06,\n",
       "       1.04333807e-07, 8.13997936e-09, 1.36889096e-08, 2.33895619e-07,\n",
       "       2.57386090e-09, 7.78955425e-08, 1.56258502e-05, 3.72761315e-06,\n",
       "       1.02235390e-04, 2.13351564e-06, 1.00356147e-05, 6.46840226e-06,\n",
       "       6.14345936e-06, 1.93810661e-06, 1.77935453e-05, 9.17895013e-12,\n",
       "       1.88015272e-12, 2.98724309e-11, 1.76629822e-11, 1.60555629e-12,\n",
       "       4.30642431e-11, 2.77153842e-13, 7.67419114e-11, 4.43633975e-12,\n",
       "       1.87042374e-12, 4.81350723e-12, 7.99952032e-12, 2.07969883e-12,\n",
       "       2.91292233e-11, 5.61379231e-13, 5.05511735e-12, 8.34934108e-05,\n",
       "       1.06536390e-04, 1.79346258e-04, 3.92170949e-03, 4.75296023e-04,\n",
       "       6.64950721e-03, 7.27453176e-03, 2.57512033e-02, 2.21580893e-04,\n",
       "       5.72716875e-04, 1.23530908e-05, 4.75817770e-02, 1.37046809e-04,\n",
       "       8.53513367e-03, 5.36824926e-04, 6.72420470e-07, 9.19201784e-03,\n",
       "       7.06418650e-03, 4.54795733e-02, 4.78864321e-03, 4.49022735e-07,\n",
       "       2.49318743e-09, 4.98357440e-06, 2.41426164e-07, 1.56180577e-05,\n",
       "       2.11168086e-07, 1.16741390e-07, 5.03310048e-07, 1.50749315e-07,\n",
       "       1.61260061e-07, 1.02463300e-05, 7.96217080e-07, 3.20821164e-06,\n",
       "       5.00276929e-06, 3.55664588e-06, 4.87209672e-06, 1.19173635e-07,\n",
       "       5.55524423e-07, 1.04592955e-05, 2.33068954e-06, 7.19053924e-06,\n",
       "       4.58623189e-03, 2.08550338e-02, 7.36395037e-03, 6.11251332e-02,\n",
       "       4.61862721e-02, 1.90449704e-03, 7.25440041e-04, 1.68384705e-02,\n",
       "       5.25860548e-01, 9.56892312e-01, 9.98105526e-01, 6.96912348e-01,\n",
       "       6.12926722e-01, 4.00936872e-01, 6.69392049e-01, 3.53681684e-01,\n",
       "       7.37029091e-02, 9.76942539e-01, 9.95440006e-01, 4.78657454e-01,\n",
       "       6.70025170e-01, 9.72189486e-01, 9.83083248e-01, 3.07191640e-01,\n",
       "       7.17651248e-01, 8.89088631e-01, 8.86170924e-01, 8.83821785e-01,\n",
       "       5.41015089e-01, 9.35684800e-01, 8.29066932e-02, 6.58729076e-01,\n",
       "       9.18017387e-01, 7.33663321e-01, 9.90162373e-01, 8.53919685e-01,\n",
       "       8.96998405e-01, 4.08732653e-01, 9.71873879e-01, 6.04192793e-01,\n",
       "       2.97620624e-01, 9.88388896e-01, 6.23685919e-05, 1.39042932e-05,\n",
       "       2.52667116e-04, 1.20712389e-06, 3.58012358e-06, 3.78232636e-02,\n",
       "       9.86401021e-01, 8.62307012e-01, 9.87488031e-01, 8.72975290e-01,\n",
       "       9.89801347e-01, 4.01519358e-01, 8.72465372e-01, 9.91246879e-01,\n",
       "       9.99026537e-01, 9.98260558e-01, 8.70115101e-01, 3.47457498e-01,\n",
       "       9.99083400e-01, 9.28051770e-01, 3.20178515e-05, 1.22519341e-05,\n",
       "       7.09660299e-07, 3.77323659e-06, 1.41056764e-04, 1.74438865e-05,\n",
       "       3.90756140e-05, 3.72980634e-04, 5.74957859e-03, 1.43604802e-05,\n",
       "       1.67662816e-04, 1.26868372e-05, 4.22283229e-05, 1.55776530e-03,\n",
       "       1.40812306e-04, 3.47389469e-05, 4.38489922e-04, 9.96449453e-05,\n",
       "       1.65237358e-03, 6.17933911e-05, 3.49571026e-04, 3.93211357e-02,\n",
       "       1.12983920e-02, 3.27712186e-02, 3.85729945e-04, 1.89502072e-02,\n",
       "       4.18278249e-03, 7.52190361e-03, 3.65338922e-02, 2.45621540e-02,\n",
       "       8.58098909e-04, 3.26164503e-04, 1.02790026e-02, 4.56020283e-03,\n",
       "       1.01322057e-02, 1.78615388e-03, 5.07726148e-03, 5.65161943e-01,\n",
       "       1.92421719e-01, 1.91723049e-01, 4.12314981e-02, 4.85620737e-01,\n",
       "       9.91396047e-03, 3.75571907e-01, 5.44228137e-01, 9.73166525e-02,\n",
       "       1.18379928e-01, 1.95136964e-02, 4.52705696e-02, 6.51800365e-04,\n",
       "       2.63407058e-03, 6.76166415e-02, 4.03789058e-02, 1.41194696e-03,\n",
       "       1.01992011e-03, 2.52796873e-03, 3.46547058e-05, 1.30794407e-03,\n",
       "       6.01966167e-04, 3.02880257e-03, 1.95816979e-02, 5.72168501e-04,\n",
       "       2.42019989e-04, 1.52019656e-03, 3.08815535e-04, 1.51999220e-02,\n",
       "       3.39048594e-04, 1.02597591e-03, 2.37485474e-05, 2.97596325e-05,\n",
       "       2.76361505e-04, 7.26111000e-04, 5.29524114e-04, 9.46127344e-03,\n",
       "       1.83835824e-03, 7.98908222e-05, 2.20114918e-04, 5.19282068e-04,\n",
       "       3.01278214e-06, 1.24638746e-07, 7.16023169e-06, 4.54598847e-09,\n",
       "       1.42494841e-07, 7.03813470e-08, 1.13108263e-06, 1.63404656e-09,\n",
       "       1.80205959e-07, 3.08179750e-07, 3.30007811e-06, 1.96489464e-06,\n",
       "       1.25020165e-07, 3.25496922e-06, 1.20117946e-07, 2.85582737e-05,\n",
       "       3.10717369e-05, 1.56882699e-04, 5.38996028e-06, 3.92324364e-05,\n",
       "       1.64463054e-05, 3.44977843e-06, 1.38043806e-05, 1.81651594e-05,\n",
       "       3.69930531e-05, 3.48409776e-06, 1.83388955e-04, 5.97404687e-06,\n",
       "       4.08786747e-08, 3.34360193e-05, 3.11237178e-04, 7.81635805e-08,\n",
       "       5.93190053e-10, 2.34661801e-09, 2.58122679e-08, 9.14182223e-08,\n",
       "       5.31075628e-09, 2.02179024e-07, 7.06051839e-09, 3.04708236e-09,\n",
       "       6.00197536e-09, 5.34913482e-08, 2.67441713e-09, 1.30272082e-09,\n",
       "       9.38037736e-09, 1.93134060e-08, 2.35068658e-08, 4.47658532e-09,\n",
       "       9.39454026e-09, 1.91465563e-08, 2.16163107e-06, 8.03078910e-06,\n",
       "       1.60749732e-05, 3.06325310e-05, 3.34306248e-03, 6.88304738e-07,\n",
       "       6.68456266e-07, 2.90774483e-06, 4.92667027e-07, 1.60591696e-06,\n",
       "       9.63369303e-07, 7.17435512e-07, 3.29744653e-05, 2.44603075e-06,\n",
       "       2.50055223e-07, 8.92705339e-06, 2.20923198e-06, 1.88535778e-05,\n",
       "       8.11746133e-07, 4.02767409e-06, 4.16251691e-03, 1.30129110e-05,\n",
       "       4.90806306e-05, 4.48047096e-04, 2.49923633e-05, 9.82640813e-07,\n",
       "       5.47114876e-04, 3.32345103e-08, 5.44284928e-09, 5.80241799e-10,\n",
       "       2.62125042e-08, 3.72494008e-10, 1.33008293e-09, 5.64088376e-09,\n",
       "       4.67122385e-09, 2.75960699e-09, 1.90684091e-09, 7.31986738e-09,\n",
       "       9.59403845e-09, 9.15618896e-01, 9.97002184e-01, 9.99500632e-01,\n",
       "       9.99866962e-01, 9.99996781e-01, 8.08654666e-01, 9.96175885e-01,\n",
       "       9.62060213e-01, 9.99820173e-01, 9.34651256e-01, 9.81144845e-01,\n",
       "       9.96603489e-01, 8.64575803e-01, 9.98985708e-01, 9.60926831e-01,\n",
       "       9.99402404e-01, 9.44226861e-01, 9.00951803e-01, 6.06649220e-01,\n",
       "       9.81701195e-01, 9.98570681e-01, 9.99596775e-01, 6.75067365e-01,\n",
       "       8.96004736e-01, 9.84526396e-01, 6.67751074e-01, 9.94806230e-01,\n",
       "       9.86806333e-01, 7.23312130e-14, 5.35549668e-15, 1.15001864e-15,\n",
       "       1.45943840e-15, 2.70118468e-15, 7.87947952e-16, 1.40584785e-16,\n",
       "       7.09597964e-18, 1.07102320e-16, 1.38302825e-16, 1.13371540e-14,\n",
       "       5.10134995e-15, 1.45243969e-16, 1.05439038e-16], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  12,  14,  16,  18,  19,  21,  22,  50,  52,  55,  57,  60,\n",
       "        63,  76,  79, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119,\n",
       "       155, 159, 160, 161, 163, 164, 165, 166, 168, 170, 171, 175, 184,\n",
       "       185, 190, 198, 205, 206, 207, 208, 209, 210, 211, 212, 214, 215,\n",
       "       217, 218, 219, 220, 221, 224, 247, 268, 269, 270, 274, 297, 302,\n",
       "       303, 317, 322, 336, 337, 339, 345, 346, 351, 353, 355, 356, 358,\n",
       "       362], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.where(scores>0.5)[0]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=15\n",
    "indices = np.argpartition(scores, -K)[-K:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999666"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(expit(np.dot(x,w)+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  _16'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_classes[74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_scores = [(mapping_classes[i], scores[i]) for i in indices]\n",
    "class_scores\n",
    "most_possible = {}\n",
    "for c, s in class_scores:\n",
    "    if c in most_possible:\n",
    "        most_possible[c].append(s)\n",
    "    else:\n",
    "        most_possible[c] = [s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _36 0.5669395 0.0\n",
      "  _12 0.6037039 0.06522206\n",
      "  _13 0.59534603 0.031525046\n",
      " _44 0.58407426 0.06576496\n",
      "  _10 0.60051274 0.061988097\n",
      "  _9 0.61844015 0.07833812\n",
      "  _3 0.66949815 0.10564791\n",
      "  _21 0.56239855 0.011429191\n",
      "  _18 0.6012496 0.09586704\n",
      "  _8 0.64786965 0.026243567\n",
      "  _19 0.6917017 0.087107524\n",
      "  _32 0.67347246 0.09362993\n",
      " _41 0.5066209 0.0\n",
      "  _29 0.5462571 0.031700887\n",
      "  _38 0.6327678 0.0\n",
      " _43 0.5463175 0.0\n",
      "  _7 0.671219 0.029287905\n",
      " _42 0.6384949 0.08891553\n",
      " _6 0.6102081 0.06587339\n"
     ]
    }
   ],
   "source": [
    "for k, v in most_possible.items():\n",
    "    print(k, np.mean(v), np.std(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('  _12', 0.7544167),\n",
       " ('  _12', 0.8870763),\n",
       " ('  _12', 0.63059896),\n",
       " ('  _12', 0.8706097),\n",
       " ('  _12', 0.8605387),\n",
       " ('  _12', 0.8062218),\n",
       " ('  _12', 0.9619535),\n",
       " ('  _9', 0.52586055),\n",
       " ('  _9', 0.9568923),\n",
       " ('  _9', 0.9981055),\n",
       " ('  _9', 0.69691235),\n",
       " ('  _9', 0.6129267),\n",
       " ('  _9', 0.66939205),\n",
       " ('  _9', 0.97694254),\n",
       " ('  _9', 0.99544),\n",
       " ('  _9', 0.67002517),\n",
       " ('  _9', 0.9721895),\n",
       " ('  _9', 0.98308325),\n",
       " ('  _9', 0.71765125),\n",
       " ('  _9', 0.88908863),\n",
       " ('  _9', 0.8861709),\n",
       " ('  _9', 0.8838218),\n",
       " ('  _9', 0.5410151),\n",
       " ('  _9', 0.9356848),\n",
       " ('  _9', 0.6587291),\n",
       " ('  _9', 0.9180174),\n",
       " ('  _9', 0.7336633),\n",
       " ('  _9', 0.9901624),\n",
       " ('  _9', 0.8539197),\n",
       " ('  _9', 0.8969984),\n",
       " ('  _9', 0.9718739),\n",
       " ('  _9', 0.6041928),\n",
       " ('  _9', 0.9883889),\n",
       " ('  _3', 0.986401),\n",
       " ('  _3', 0.862307),\n",
       " ('  _3', 0.98748803),\n",
       " ('  _3', 0.8729753),\n",
       " ('  _3', 0.98980135),\n",
       " ('  _3', 0.8724654),\n",
       " ('  _3', 0.9912469),\n",
       " ('  _3', 0.99902654),\n",
       " ('  _3', 0.99826056),\n",
       " ('  _3', 0.8701151),\n",
       " ('  _3', 0.9990834),\n",
       " ('  _3', 0.92805177),\n",
       " ('  _19', 0.56516194),\n",
       " ('  _19', 0.54422814),\n",
       " (' _6', 0.9156189),\n",
       " (' _6', 0.9970022),\n",
       " (' _6', 0.99950063),\n",
       " (' _6', 0.99986696),\n",
       " (' _6', 0.9999968),\n",
       " (' _6', 0.80865467),\n",
       " (' _6', 0.9961759),\n",
       " (' _6', 0.9620602),\n",
       " (' _6', 0.9998202),\n",
       " (' _6', 0.93465126),\n",
       " (' _6', 0.98114485),\n",
       " (' _6', 0.9966035),\n",
       " (' _6', 0.8645758),\n",
       " (' _6', 0.9989857),\n",
       " (' _6', 0.96092683),\n",
       " (' _6', 0.9994024),\n",
       " (' _6', 0.94422686),\n",
       " (' _6', 0.9009518),\n",
       " (' _6', 0.6066492),\n",
       " (' _6', 0.9817012),\n",
       " (' _6', 0.9985707),\n",
       " (' _6', 0.9995968),\n",
       " (' _6', 0.67506737),\n",
       " (' _6', 0.89600474),\n",
       " (' _6', 0.9845264),\n",
       " (' _6', 0.6677511),\n",
       " (' _6', 0.99480623),\n",
       " (' _6', 0.98680633)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('  _14', 1.0),\n",
       " ('  _13', 1.0),\n",
       " (' _44', 1.0)]"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(most_possible.items(), key=lambda item: item[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('  _10', array(['0.8518551', '0.83667743'], dtype='<U20')),\n",
       " (' _22', array(['0.82544804', '0.77438444'], dtype='<U10')),\n",
       " ('  _4',\n",
       "  array(['0.96198285', '0.99813855', '0.9960905', '0.99992895',\n",
       "         '0.99999666', '0.9718878', '0.96991897'], dtype='<U15'))]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, (np.array(list(l))[:,1])) for k, l  in groupby(class_scores, lambda x:x[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.groupby at 0x25abf5e7f10>"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby(class_scores, lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' _36', ' _11', '  _12',\n",
       "       '  _14', '  _13', ' _44',\n",
       "       '  _16', '  _10',\n",
       "       '  _9', '  _3',\n",
       "       '  _21', '  _18',\n",
       "       '  _8', '  _19', ' _22',\n",
       "       '  _33', '  _29', '  _38',\n",
       "       '  _2', ' _43', '  _7',\n",
       "       '  _23', ' _6', '  _4'],\n",
       "      dtype='<U22')"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list = np.unique(mapping_classes)\n",
    "labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _10\\\\VID_20200217_185954_ecf52e.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _10\\\\VID_20200217_193008_714329.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\ _22\\\\CAM00003_0379ce4be376405083f8f96a7fdda46e.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\ _22\\\\CAM00003_5d19fa94febd48a4a8ba693339ca7c36.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _4\\\\CAM00003_003f646b01d144b095a8d19f641dcf02.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _4\\\\CAM00003_2d227a9b5f4347edb08dea48133c605b.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _4\\\\CAM00003_2f90de8ae52b47db88f9b3e3b198077c.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _4\\\\CAM00003_34b1e79b23b54577a15fabbbe2a85f4f.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _4\\\\CAM00003_76f5f6e12b454dba8eb8417e5eeecc59.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _4\\\\CAM00003_7d230ee7d3af4e2d9c3a33dec8861e32.jpg',\n",
       "       'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _4\\\\f55b023d136a469592d0c2bb7a515578.jpg'],\n",
       "      dtype='<U92')"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mapping_files)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9908873 , 0.9928229 , 0.9929639 , 0.9947424 , 0.99476033,\n",
       "       0.9950682 , 0.99613404, 0.99529904, 0.99680245, 0.99996305,\n",
       "       0.9968208 , 0.99955434, 0.9991129 , 0.9987306 , 0.9995023 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([' _11', '  _9', '  _21',\n",
       "        '  _8', '  _19', ' _22'],\n",
       "       dtype='<U22'), array([1, 4, 4, 1, 2, 3], dtype=int64))"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(values,counts) = np.unique(np.array(mapping_classes)[indices],return_counts=True)\n",
    "(values,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([' _22'], dtype='<U22'), array([3], dtype=int64))"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  _33'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 64)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.      ,  0.      ,  9.895573,  0.      ,  0.      , 30.561514,\n",
       "       27.17593 , 20.026007,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      , 32.7002  ,  0.      ,  0.      , 31.940073, 14.668335,\n",
       "        0.      , 20.192516,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      , 42.856277,  0.      , 29.251688, 16.613678,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "       13.600231,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "       29.68519 ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      , 34.80243 , 10.774771,  0.      ,\n",
       "       10.204382,  0.      ,  0.      ,  0.      , 18.60993 , 18.822977,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ], dtype=float32)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 64), (1,))"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5538806e-12],\n",
       "       [8.7822236e-11],\n",
       "       [4.5586152e-12],\n",
       "       [5.6297963e-11],\n",
       "       [5.1387922e-11],\n",
       "       [7.9003996e-01],\n",
       "       [5.4325867e-01],\n",
       "       [9.9967325e-01],\n",
       "       [9.9908948e-01],\n",
       "       [5.9550645e-20]], dtype=float32)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(expit(np.dot(x,w)+b))[11:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices=26 #TODO: remove\n",
    "embeddings = [[]]*class_indices\n",
    "for i in range(class_indices):\n",
    "    for j in range(len(arrays_per_label[i])):\n",
    "        embeddings[i].append(recognizer._basic_model.predict(np.expand_dims(arrays_per_label[i][j], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54326606, 0.54326606]], dtype=float32)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[i][j].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.vstack([embeddings[i][j], embeddings[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\ _11\\\\CAM00003_8fff131ae2bd4c519c38594bfa2ccb0b.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\ _11\\\\CAM00003_9147112a1f2f407b9a0a8de09b55ebeb.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\ _11\\\\CAM00003_a475afbb161f471d8ae5ddc39b6faa66.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\ _11\\\\CAM00003_c181d5f6a0ba4051bfb5ce6aad08b736.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\ _11\\\\CAM00003_ea20766d519a4d12b0c8a484b8773511.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _12\\\\CAM00003_15ed234ed5f143d38915126022fbf9df.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _12\\\\CAM00003_259aa7a0af4d4b89919873d8ef13991a.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _12\\\\CAM00003_f5af2765ba254948ade4cbe6082778f4.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _12\\\\CAM00003_fcf13044493643bb9b70ba967dd316f5.jpg',\n",
       " 'd:\\\\ML\\\\data\\\\f\\\\images\\\\out\\\\  _14\\\\CAM00003_3af90fb8312948fe8cb4c84980d8e13c.jpg']"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_files[11:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'sequential_20/Identity:0' shape=(None, 64) dtype=float32>,\n",
       " <tf.Tensor 'sequential_20_1/Identity:0' shape=(None, 64) dtype=float32>]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer._similarity_model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[i][j].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_per_label = recognizer.prepare_images_from_dir(path)\n",
    "X, Y = recognizer.prepare_pairs(arrays_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML\\\\data\\\\f\\\\images\\\\out'"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'batch_size' : 32 ,\n",
    "    'epochs' : 20 ,\n",
    "    'callbacks' : None , # [ TensorBoard( log_dir='logs/{}'.format( time.time() ) ) ] ,\n",
    "    'validation_data' : None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6030, 150, 60, 3)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:, 0, :,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = x_train[:,0,:,:,:]\n",
    "X2 = x_train[:,1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-5d20199f4c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    607\u001b[0m   \u001b[1;31m# As a fallback for the data type that does not work with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m   \u001b[1;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m                **kwargs):\n\u001b[0;32m    216\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_numpy_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_numpy_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_numpy_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_numpy_inputs\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_non_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m   \u001b[1;31m# For more complicated structure, we only convert the out most list to tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m   \u001b[1;31m# since dataset will stack the list, but treat elements in the tuple as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_non_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;31m# `SparseTensors` can't be converted to `Tensor`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[0;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[0;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[1;32m-> 1184\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    225\u001b[0m   \"\"\"\n\u001b[0;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 227\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recognizer._model.fit([X1, X2], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.12452415],\n",
       "        [ 0.09079502],\n",
       "        [ 0.03064282],\n",
       "        [ 0.07271424],\n",
       "        [-0.05793344],\n",
       "        [-0.2663393 ],\n",
       "        [-0.14829277],\n",
       "        [-0.28353915],\n",
       "        [-0.18515424],\n",
       "        [-0.26085302],\n",
       "        [ 0.14630626],\n",
       "        [ 0.27739662],\n",
       "        [-0.18752863],\n",
       "        [-0.17392169],\n",
       "        [-0.15702446],\n",
       "        [-0.09803367],\n",
       "        [-0.07001007],\n",
       "        [-0.02977801],\n",
       "        [-0.0023493 ],\n",
       "        [-0.13726158],\n",
       "        [-0.05140093],\n",
       "        [-0.01243227],\n",
       "        [ 0.19566163],\n",
       "        [ 0.17835909],\n",
       "        [-0.00054232],\n",
       "        [-0.26771128],\n",
       "        [ 0.1869823 ],\n",
       "        [-0.0862117 ],\n",
       "        [ 0.08208051],\n",
       "        [ 0.19245052],\n",
       "        [ 0.26505953],\n",
       "        [ 0.11447033],\n",
       "        [-0.25132498],\n",
       "        [ 0.24162523],\n",
       "        [ 0.04448824],\n",
       "        [ 0.116676  ],\n",
       "        [ 0.16571474],\n",
       "        [ 0.2923946 ],\n",
       "        [ 0.07219257],\n",
       "        [-0.05919583],\n",
       "        [ 0.27779028],\n",
       "        [ 0.2653152 ],\n",
       "        [ 0.11637916],\n",
       "        [ 0.16086672],\n",
       "        [ 0.16578145],\n",
       "        [-0.04093098],\n",
       "        [ 0.1809016 ],\n",
       "        [ 0.21610698],\n",
       "        [ 0.1541903 ],\n",
       "        [-0.07003321],\n",
       "        [-0.16154097],\n",
       "        [ 0.03287835],\n",
       "        [ 0.10582947],\n",
       "        [ 0.18995573],\n",
       "        [ 0.18600726],\n",
       "        [ 0.28969672],\n",
       "        [ 0.15573701],\n",
       "        [ 0.14082   ],\n",
       "        [-0.05613015],\n",
       "        [ 0.16055849],\n",
       "        [ 0.0231466 ],\n",
       "        [ 0.28963915],\n",
       "        [-0.08514363],\n",
       "        [-0.03281989]], dtype=float32), array([0.05114586], dtype=float32)]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer._similarity_model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5478 samples\n",
      "Epoch 1/20\n",
      "5478/5478 [==============================] - 72s 13ms/sample - loss: 2.5698e-04\n",
      "Epoch 2/20\n",
      "5478/5478 [==============================] - 67s 12ms/sample - loss: 1.2297e-04\n",
      "Epoch 3/20\n",
      "5478/5478 [==============================] - 64s 12ms/sample - loss: 9.2845e-05\n",
      "Epoch 4/20\n",
      "5478/5478 [==============================] - 65s 12ms/sample - loss: 7.5423e-05\n",
      "Epoch 5/20\n",
      "5478/5478 [==============================] - 63s 11ms/sample - loss: 6.3373e-05\n",
      "Epoch 6/20\n",
      "5478/5478 [==============================] - 63s 11ms/sample - loss: 5.4226e-05\n",
      "Epoch 7/20\n",
      "5478/5478 [==============================] - 64s 12ms/sample - loss: 4.7013e-05\n",
      "Epoch 8/20\n",
      "5478/5478 [==============================] - 64s 12ms/sample - loss: 4.1204e-05\n",
      "Epoch 9/20\n",
      "5478/5478 [==============================] - 64s 12ms/sample - loss: 3.6336e-05\n",
      "Epoch 10/20\n",
      "5478/5478 [==============================] - 63s 11ms/sample - loss: 3.2218e-05\n",
      "Epoch 11/20\n",
      "5478/5478 [==============================] - 63s 11ms/sample - loss: 2.8641e-05\n",
      "Epoch 12/20\n",
      "5478/5478 [==============================] - 64s 12ms/sample - loss: 2.5626e-05\n",
      "Epoch 13/20\n",
      "5478/5478 [==============================] - 62s 11ms/sample - loss: 2.2999e-05\n",
      "Epoch 14/20\n",
      "5478/5478 [==============================] - 63s 11ms/sample - loss: 2.0736e-05\n",
      "Epoch 15/20\n",
      "5478/5478 [==============================] - 62s 11ms/sample - loss: 1.8678e-05\n",
      "Epoch 16/20\n",
      "5478/5478 [==============================] - 62s 11ms/sample - loss: 1.6855e-05\n",
      "Epoch 17/20\n",
      "5478/5478 [==============================] - 62s 11ms/sample - loss: 1.5254e-05\n",
      "Epoch 18/20\n",
      "5478/5478 [==============================] - 62s 11ms/sample - loss: 1.3823e-05\n",
      "Epoch 19/20\n",
      "5478/5478 [==============================] - 62s 11ms/sample - loss: 1.2530e-05\n",
      "Epoch 20/20\n",
      "5478/5478 [==============================] - 62s 11ms/sample - loss: 1.1355e-05\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           [(None, 150, 60, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           [(None, 150, 60, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_20 (Sequential)      (None, 64)           5671930     input_39[0][0]                   \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_21 (Sequential)      (None, 1)            65          sequential_20[1][0]              \n",
      "                                                                 sequential_20[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,671,995\n",
      "Trainable params: 5,671,995\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Elapsed time acquired -> 21.29478444258372 minutes\n"
     ]
    }
   ],
   "source": [
    "recognizer.fit(x_train, y_train, **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51156"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.save_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 2, 150, 60, 3)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1826/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 9s 5ms/sample - loss: 0.0127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02549400829453764"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_thumb_size\n",
    "inversed_max_thumb_size=(max_thumb_size[1], max_thumb_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 285 images belonging to 26 classes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-9518065c6a75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_to_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'd:\\ML\\data\\f\\images\\out5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0minversed_max_thumb_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug = ImageDataGenerator(rotation_range=10, rescale=1./255, fill_mode='constant')\n",
    "\n",
    "gen = aug.flow_from_directory(path, save_to_dir = r'd:\\ML\\data\\f\\images\\out5', target_size= inversed_max_thumb_size)\n",
    "a = next(gen)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x25af9c2ed30>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 150, 60, 3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= next(gen)\n",
    "a[0].shape, a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 150, 60, 3), (32, 26))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= next(gen)\n",
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(a[1])\n",
    "y=np.zeros((batch_size,))                \n",
    "for i in range (batch_size):\n",
    "    y[i] = np.array_equal(a[1][i], b[1][i])\n",
    "y                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepared_generator(gen):\n",
    "    while True:\n",
    "        a= next(gen)\n",
    "        b= next(gen)\n",
    "        batch_size = len(a[1])\n",
    "        y=np.zeros((batch_size,))                \n",
    "        for i in range (batch_size):\n",
    "            y[i] = np.array_equal(a[1][i], b[1][i])\n",
    "\n",
    "        yield ([a[0], b[0]], y)              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 285 images belonging to 26 classes.\n",
      "!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([[[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.3382498 , 0.18923017, 0.13824978],\n",
       "           [0.34178194, 0.19276233, 0.14223053],\n",
       "           [0.34159517, 0.19257554, 0.14943829],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.3446119 , 0.28927994, 0.23840527],\n",
       "           [0.34103864, 0.27060384, 0.22337016],\n",
       "           [0.35737574, 0.2708852 , 0.22794133]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.07684927, 0.07241721, 0.04372925],\n",
       "           [0.0964352 , 0.07586554, 0.0567202 ],\n",
       "           [0.129971  , 0.09537888, 0.08468736]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.34590855, 0.24469282, 0.20946409],\n",
       "           [0.3466615 , 0.24077918, 0.2133282 ],\n",
       "           [0.34509805, 0.23451534, 0.20941454],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]]], dtype=float32),\n",
       "  array([[[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.67904234, 0.6986502 , 0.6829639 ],\n",
       "           [0.6791549 , 0.6987627 , 0.68307644],\n",
       "           [0.6798504 , 0.6988752 , 0.6849382 ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.6817436 , 0.7019608 , 0.6862745 ],\n",
       "           [0.68163115, 0.7019608 , 0.6862745 ],\n",
       "           [0.6819893 , 0.70206094, 0.6876864 ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.5572358 , 0.56543314, 0.5105312 ],\n",
       "           [0.5568628 , 0.5647059 , 0.50980395],\n",
       "           [0.55842084, 0.56548494, 0.510583  ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.5514899 , 0.56577057, 0.5082639 ],\n",
       "           [0.55091   , 0.5647059 , 0.5068276 ],\n",
       "           [0.55349183, 0.5675127 , 0.5095219 ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.6611569 , 0.64958733, 0.6004702 ],\n",
       "           [0.66021705, 0.6482658 , 0.5993395 ],\n",
       "           [0.6673226 , 0.6475369 , 0.5963786 ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.48351276, 0.22532852, 0.2300964 ],\n",
       "           [0.47912523, 0.22848432, 0.2313567 ],\n",
       "           [0.46898317, 0.24194054, 0.23805083],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]],\n",
       "  \n",
       "  \n",
       "         [[[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.74672776, 0.75251704, 0.75475717],\n",
       "           [0.7583933 , 0.76470596, 0.7653758 ],\n",
       "           [0.76154536, 0.7684113 , 0.76742136]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.3648203 , 0.3530556 , 0.31776148],\n",
       "           [0.2863936 , 0.2746289 , 0.23933478],\n",
       "           [0.21983093, 0.21554558, 0.17775834],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        ]]]], dtype=float32)],\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "class PairGenerator(keras.preprocessing.image.DirectoryIterator):\n",
    "    def __init__(self, gen):\n",
    "        super().__init__(gen.directory, gen.image_data_generator)\n",
    "        self.gen = gen\n",
    "    def __next__(self):\n",
    "        print('!')\n",
    "        while True:\n",
    "            a= next(self.gen)\n",
    "            b= next(self.gen)\n",
    "            batch_size = self.batch_size\n",
    "            y=np.zeros((len(a[1]),))                \n",
    "            for i in range (batch_size):\n",
    "                y[i] = np.array_equal(a[1][i], b[1][i])\n",
    "\n",
    "            yield [a[0], b[0]], y             \n",
    "\n",
    "pair_gen = PairGenerator(gen)       \n",
    "next(next(pair_gen))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-d189974e47fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepared_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepared_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "gener = iter(prepared_generator)\n",
    "next(prepared_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
