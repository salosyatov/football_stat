{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm.notebook'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-383a2f419b44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm.notebook'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "PATH = \"/kaggle/input/digit-recognizer/\"\n",
    "\n",
    "torch.manual_seed(2020)\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 2\n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH+\"train.csv\")\n",
    "test_df = pd.read_csv(PATH+\"test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define class MNIST\n",
    "I'll define `class MNIST` which was inherited `torch.utils.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    def __init__(self, df, train=True, transform=None):\n",
    "        self.is_train = train\n",
    "        self.transform = transform\n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "        \n",
    "        if self.is_train:            \n",
    "            self.images = df.iloc[:, 1:].values.astype(np.uint8)\n",
    "            self.labels = df.iloc[:, 0].values\n",
    "            self.index = df.index.values\n",
    "        else:\n",
    "            self.images = df.values.astype(np.uint8)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        anchor_img = self.images[item].reshape(28, 28, 1)\n",
    "        \n",
    "        if self.is_train:\n",
    "            anchor_label = self.labels[item]\n",
    "\n",
    "            positive_list = self.index[self.index!=item][self.labels[self.index!=item]==anchor_label]\n",
    "\n",
    "            positive_item = random.choice(positive_list)\n",
    "            positive_img = self.images[positive_item].reshape(28, 28, 1)\n",
    "            \n",
    "            negative_list = self.index[self.index!=item][self.labels[self.index!=item]!=anchor_label]\n",
    "            negative_item = random.choice(negative_list)\n",
    "            negative_img = self.images[negative_item].reshape(28, 28, 1)\n",
    "            \n",
    "            if self.transform:\n",
    "                anchor_img = self.transform(self.to_pil(anchor_img))\n",
    "                positive_img = self.transform(self.to_pil(positive_img))\n",
    "                negative_img = self.transform(self.to_pil(negative_img))\n",
    "            \n",
    "            return anchor_img, positive_img, negative_img, anchor_label\n",
    "        \n",
    "        else:\n",
    "            if self.transform:\n",
    "                anchor_img = self.transform(self.to_pil(anchor_img))\n",
    "            return anchor_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNIST(train_df, \n",
    "                 train=True,\n",
    "                 transform=transforms.Compose([\n",
    "                     transforms.ToTensor()\n",
    "                 ]))\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MNIST(test_df, train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, emb_dim=128):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(512, emb_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        # x = nn.functional.normalize(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Instances\n",
    "Use JIT compilation for high speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(embedding_dims)\n",
    "model.apply(init_weights)\n",
    "model = torch.jit.script(model).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.jit.script(TripletLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    running_loss = []\n",
    "    for step, (anchor_img, positive_img, negative_img, anchor_label) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "        anchor_img = anchor_img.to(device)\n",
    "        positive_img = positive_img.to(device)\n",
    "        negative_img = negative_img.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        anchor_out = model(anchor_img)\n",
    "        positive_out = model(positive_img)\n",
    "        negative_out = model(negative_img)\n",
    "        \n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "    print(\"Epoch: {}/{} - Loss: {:.4f}\".format(epoch+1, epochs, np.mean(running_loss)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"model_state_dict\": model.state_dict(),\n",
    "            \"optimzier_state_dict\": optimizer.state_dict()\n",
    "           }, \"trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = []\n",
    "labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img, _, _, label in tqdm(train_loader):\n",
    "        train_results.append(model(img.to(device)).cpu().numpy())\n",
    "        labels.append(label)\n",
    "        \n",
    "train_results = np.concatenate(train_results)\n",
    "labels = np.concatenate(labels)\n",
    "train_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), facecolor=\"azure\")\n",
    "for label in np.unique(labels):\n",
    "    tmp = train_results[labels==label]\n",
    "    plt.scatter(tmp[:, 0], tmp[:, 1], label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = XGBClassifier(seed=2020)\n",
    "tree.fit(train_results, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "test_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img in tqdm(test_loader):\n",
    "        test_results.append(model(img.to(device)).cpu().numpy())\n",
    "        \n",
    "test_results = np.concatenate(test_results)\n",
    "\n",
    "plt.figure(figsize=(15, 10), facecolor=\"azure\")\n",
    "plt.scatter(test_results[:, 0], test_results[:, 1], label=label)\n",
    "\n",
    "test_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(PATH+\"sample_submission.csv\")\n",
    "submit.Label = tree.predict(test_results)\n",
    "\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
